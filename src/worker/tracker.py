import asyncio
import logging
import httpx
from datetime import datetime
from sqlalchemy import select, func, case
from src.database import async_session_maker, init_db
from src.models import Pool, Transaction, Wallet
from src.config import settings
from src.worker.transactions import TransactionProcessor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)



class JettonTracker:
    def __init__(self):
        self.is_running = False
        self.delay = 1.0 / settings.requests_per_second
        self.batch_size = settings.worker_batch_size
        self.processor = TransactionProcessor()
        self.sse_monitors = []
        self.processing_lock = asyncio.Lock()  # üîí –¢–æ–ª—å–∫–æ –æ–¥–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞ —Ä–∞–∑
    
    async def start(self):
        logger.info(f"üöÄ Starting Jetton Tracker...")
        logger.info(f"Rate limit: {settings.requests_per_second} req/sec")
        logger.info(f"Batch size: {self.batch_size}")
        
        await init_db()
        await self.ensure_leaderboard_ready()
        await self.initial_pool_sync()
        
        self.is_running = True
        
        while self.is_running:
            try:
                synced = await self.sync_new_wallets()
                
                processed = await self.process_pending_transactions()
                
                if synced == 0 and processed == 0:
                    await asyncio.sleep(5)
                
            except Exception as e:
                logger.error(f"Error in tracker loop: {e}")
                await asyncio.sleep(10)
    
    async def stop(self):
        logger.info("Stopping Jetton tracker...")
        self.is_running = False
        
        for monitor in self.sse_monitors:
            monitor.stop()
        
        await self.processor.close()
    
    async def initial_pool_sync(self):
        logger.info("üîÑ Starting initial pool sync...")
        sync_start_time = asyncio.get_event_loop().time()
        
        async with async_session_maker() as db:
            result = await db.execute(select(Pool).where(Pool.is_active == True))
            pools = result.scalars().all()
            
            if not pools:
                logger.warning("No active pools found for sync")
                return
            
            for pool in pools:
                pool_sync_start = asyncio.get_event_loop().time()
                
                # üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –µ—Å–ª–∏ –µ—Å—Ç—å last_processed_lt, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –ù–û–í–´–• —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
                if pool.last_processed_lt:
                    logger.info(f"üìÖ Pool {pool.name}: fetching NEW transactions after LT {pool.last_processed_lt}")
                    all_txs = await self.fetch_pool_transactions(
                        pool_address=pool.address,
                        after_lt=pool.last_processed_lt
                    )
                else:
                    # –ò–Ω–∞—á–µ –Ω–∞—á–∏–Ω–∞–µ–º —Å START_DATE (–ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫)
                    start_timestamp = int(datetime.strptime(settings.start_date, "%Y-%m-%d").timestamp())
                    logger.info(f"üìÖ Pool {pool.name}: first sync - fetching transactions from {settings.start_date}")
                    all_txs = await self.fetch_pool_transactions(
                        pool_address=pool.address,
                        start_timestamp=start_timestamp
                    )
                
                try:
                    added = 0
                    logger.info(f"üíæ Adding {len(all_txs)} transactions to database...")
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º last_processed_lt –≤ —á–∏—Å–ª–æ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                    stop_at_lt = int(pool.last_processed_lt) if pool.last_processed_lt else 0
                    if stop_at_lt > 0:
                        logger.info(f"‚õî Will skip transactions already processed (LT <= {stop_at_lt})")
                    
                    # –ü—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –í–°–ï TX, –Ω–µ –ø—Ä–æ–≤–µ—Ä—è—è LAMBO
                    # LAMBO –ø—Ä–æ–≤–µ—Ä–∫–∞ –±—É–¥–µ—Ç –ø–æ–∑–∂–µ –≤ process_pending_transactions()
                    for tx_data in all_txs:
                        tx_lt = int(tx_data["lt"])
                        
                        # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π LT, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
                        # (TX –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –æ—Ç –Ω–æ–≤—ã—Ö –∫ —Å—Ç–∞—Ä—ã–º, —Ç–∞–∫ —á—Ç–æ –≤—Å–µ —Å–ª–µ–¥—É—é—â–∏–µ –±—É–¥—É—Ç —Å—Ç–∞—Ä—à–µ)
                        if stop_at_lt > 0 and tx_lt <= stop_at_lt:
                            logger.info(f"‚õî Reached previously processed LT {tx_lt}, stopping (checkpoint was {stop_at_lt})")
                            break
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç –≤ –ë–î
                        existing = await db.execute(
                            select(Transaction).where(Transaction.tx_hash == tx_data["hash"])
                        )
                        if existing.scalar_one_or_none():
                            logger.debug(f"   Skipping duplicate TX {tx_data['hash']}")
                            continue
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º TX –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ - –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –ø—Ä–æ–≤–µ—Ä–∏—Ç LAMBO –ø–æ–∑–∂–µ
                        tx = Transaction(
                            tx_hash=tx_data["hash"],
                            lt=str(tx_data["lt"]),
                            timestamp=tx_data["utime"],
                            pool_id=pool.id,
                            is_processed=False
                        )
                        db.add(tx)
                        added += 1
                        
                        # Commit –∫–∞–∂–¥—ã–µ 100 —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
                        if added % 100 == 0:
                            await db.commit()
                            logger.info(f"   Progress: {added} transactions added")
                    
                    # –§–∏–Ω–∞–ª—å–Ω—ã–π commit
                    await db.commit()
                    logger.info(f"üìä Added: {added} new transactions to process later (out of {len(all_txs)} fetched)")
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º last_processed_lt - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π LT –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö
                    if all_txs:
                        if stop_at_lt > 0:
                            # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π LT –∏–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –í–´–®–µ checkpoint
                            new_txs = [int(tx["lt"]) for tx in all_txs if int(tx["lt"]) > stop_at_lt]
                            if new_txs:
                                latest_lt = max(new_txs)
                                pool.last_processed_lt = str(latest_lt)
                                pool.last_sync_timestamp = int(datetime.utcnow().timestamp())
                                await db.commit()
                                logger.info(f"‚úÖ Pool {pool.name}: checkpoint updated to LT {latest_lt}")
                            else:
                                logger.info(f"‚è≠Ô∏è  No new transactions above checkpoint, keeping LT {stop_at_lt}")
                        else:
                            # –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ - –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π LT –∏–∑ –≤—Å–µ—Ö
                            latest_lt = max(int(tx["lt"]) for tx in all_txs)
                            pool.last_processed_lt = str(latest_lt)
                            pool.last_sync_timestamp = int(datetime.utcnow().timestamp())
                            await db.commit()
                            logger.info(f"‚úÖ Pool {pool.name}: checkpoint saved to LT {latest_lt}")
                    
                    pool_sync_time = asyncio.get_event_loop().time() - pool_sync_start
                    logger.info(f"‚è±Ô∏è  Pool sync time: {pool_sync_time:.2f}s")
                    
                except Exception as e:
                    logger.error(f"‚ùå Error syncing pool {pool.name}: {e}")
        
        total_sync_time = asyncio.get_event_loop().time() - sync_start_time
        logger.info(f"‚úÖ Initial pool sync complete (total time: {total_sync_time:.2f}s)")
    
    async def fetch_pool_transactions(self, pool_address: str, start_timestamp: int = None, after_lt: str = None) -> list:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–µ—Ä—Å–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ö–û–ù–í–ï–ô–ï–† (pipeline) –≤–º–µ—Å—Ç–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –æ–¥–Ω–æ–π LT
        
        –í–º–µ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤–∫–∏ 10 –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –æ–¥–Ω–æ–π before_lt:
        - –ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç LT –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ
        - –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        - –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π RPS –∫–æ–Ω—Ç—Ä–æ–ª—å
        
        –í–ê–ñ–ù–û: –ö–æ–≥–¥–∞ after_lt —É–∫–∞–∑–∞–Ω (–Ω–µ –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫):
        - –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –ë–ï–ó before_lt (–ø–æ–ª—É—á–∏–º —Å–∞–º—ã–µ –Ω–æ–≤—ã–µ!)
        - –ü—Ä–æ–≤–µ—Ä–∏–º –µ—Å—Ç—å –ª–∏ —Ç–∞–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤—ã—à–µ checkpoint
        - –ü–æ—Ç–æ–º –∏—â–µ–º –¥–∞–ª—å—à–µ –≤–Ω–∏–∑ —Å before_lt –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        """
        url = f"{settings.ton_api_url}/v2/blockchain/accounts/{pool_address}/transactions"
        all_transactions = []
        target_rps = settings.requests_per_second
        
        if after_lt:
            logger.info(f"Fetching new transactions after LT {after_lt}")
        
        logger.info(f"üöÄ Starting pipeline fetch - Target: {target_rps} RPS")
        
        async def fetch_page(client, before_lt=None):
            """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π"""
            params = {"limit": 1000}
            if before_lt:
                params["before_lt"] = before_lt
            
            request_start = asyncio.get_event_loop().time()
            try:
                response = await client.get(url, params=params)
                response.raise_for_status()
                request_time = asyncio.get_event_loop().time() - request_start
                data = response.json()
                transactions = data.get("transactions", [])
                return transactions, request_time
            except Exception as e:
                logger.error(f"Error fetching page: {e}")
                return [], 0
        
        async with httpx.AsyncClient(
            timeout=30.0,
            headers={'Authorization': f'Bearer {settings.ton_api_key}'}
        ) as client:
            fetch_start = asyncio.get_event_loop().time()
            total_requests = 0
            request_times = []
            
            # –ö–û–ù–í–ï–ô–ï–†: –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç LT –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ
            current_before_lt = None  # –ù–∞—á–∏–Ω–∞–µ–º –ë–ï–ó before_lt, –¥–∞–∂–µ –µ—Å–ª–∏ after_lt –µ—Å—Ç—å!
            first_page = True
            
            while True:
                # –ü–æ–ª—É—á–∞–µ–º –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É
                page, req_time = await fetch_page(client, current_before_lt)
                total_requests += 1
                request_times.append(req_time)
                
                if not page:
                    logger.info(f"No more transactions, total: {len(all_transactions)}")
                    break
                
                all_transactions.extend(page)
                logger.info(f"Fetched {len(page)} transactions (total: {len(all_transactions)}), LT range: {page[0]['lt']} -> {page[-1]['lt']}")
                
                # –ù–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫
                if first_page and after_lt:
                    first_page = False
                    max_lt_in_page = int(page[0]["lt"])
                    if max_lt_in_page <= int(after_lt):
                        logger.info(f"‚úÖ Max LT in first page {max_lt_in_page} <= checkpoint {after_lt}, no new transactions")
                        break
                    else:
                        logger.info(f"üìà Found newer transactions! Max LT: {max_lt_in_page} > checkpoint {after_lt}")
                
                first_page = False
                
                # –£—Å–ª–æ–≤–∏—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                if len(page) < 1000:
                    logger.info(f"Reached last page (only {len(page)} transactions), stopping")
                    break
                
                # –í–ê–ñ–ù–û: –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ (after_lt —É–∫–∞–∑–∞–Ω), –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–æ—à–ª–∏ –¥–æ checkpoint
                if after_lt and page:
                    min_lt_in_page = int(page[-1]["lt"])  # —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π LT –Ω–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                    if min_lt_in_page <= int(after_lt):
                        logger.info(f"‚úÖ Reached checkpoint LT {after_lt}, stopping (min LT in page: {min_lt_in_page})")
                        break
                
                if not after_lt and start_timestamp and page:
                    last_tx_time = int(page[-1]["utime"])
                    if last_tx_time <= start_timestamp:
                        logger.info(f"Reached start_timestamp {start_timestamp}, stopping")
                        break
                
                # –û–±–Ω–æ–≤–ª—è–µ–º before_lt –¥–ª—è –°–õ–ï–î–£–Æ–©–ï–ì–û –∑–∞–ø—Ä–æ—Å–∞
                current_before_lt = str(page[-1]["lt"])
                
                # –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º RPS: –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É
                if total_requests > 0:
                    elapsed = asyncio.get_event_loop().time() - fetch_start
                    current_rps = total_requests / max(elapsed, 0.1)
                    if current_rps > target_rps:
                        delay = (total_requests - 1) / target_rps - elapsed
                        if delay > 0:
                            await asyncio.sleep(delay)
                            logger.debug(f"RPS throttle: {current_rps:.1f} ‚Üí sleeping {delay:.3f}s")
        
        fetch_time = asyncio.get_event_loop().time() - fetch_start
        actual_rps = total_requests / max(fetch_time, 0.1)
        avg_req_time = sum(request_times) / len(request_times) if request_times else 0
        
        logger.info(f"üìä Pipeline fetch complete: {len(all_transactions)} tx from {total_requests} requests in {fetch_time:.2f}s")
        logger.info(f"   Avg RPS: {actual_rps:.1f}, Avg req time: {avg_req_time:.3f}s")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ timestamp (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ after_lt –Ω–µ —É–∫–∞–∑–∞–Ω)
        if not after_lt and start_timestamp:
            before_filter = len(all_transactions)
            all_transactions = [tx for tx in all_transactions if int(tx["utime"]) >= start_timestamp]
            filtered_out = before_filter - len(all_transactions)
            logger.info(f"After filtering by timestamp: {len(all_transactions)} transactions (removed {filtered_out})")
        
        return all_transactions
    
    async def sync_new_wallets(self) -> int:
        async with async_session_maker() as db:
            result = await db.execute(
                select(Wallet).where(
                    Wallet.sync_status == 'pending',
                    Wallet.is_active == True
                ).limit(5)
            )
            wallets = result.scalars().all()
            
            if not wallets:
                return 0
            
            logger.info(f"üîÑ Syncing {len(wallets)} new wallets...")
            
            for wallet in wallets:
                wallet.sync_status = 'syncing'
                await db.commit()
                
                result = await db.execute(
                    select(
                        func.coalesce(func.sum(case((Transaction.operation_type == 'buy', Transaction.lambo_amount), else_=0)), 0).label('buy_lambo'),
                        func.coalesce(func.sum(case((Transaction.operation_type == 'buy', Transaction.ton_amount), else_=0)), 0).label('buy_ton'),
                        func.coalesce(func.sum(case((Transaction.operation_type == 'buy', Transaction.ton_amount * Transaction.ton_usd_price), else_=0)), 0).label('buy_usd'),
                        func.coalesce(func.sum(case((Transaction.operation_type == 'sell', Transaction.lambo_amount), else_=0)), 0).label('sell_lambo'),
                        func.coalesce(func.sum(case((Transaction.operation_type == 'sell', Transaction.ton_amount), else_=0)), 0).label('sell_ton'),
                        func.coalesce(func.sum(case((Transaction.operation_type == 'sell', Transaction.ton_amount * Transaction.ton_usd_price), else_=0)), 0).label('sell_usd'),
                        func.count(Transaction.id).label('tx_count')
                    )
                    .where(
                        Transaction.user_address == wallet.address,
                        Transaction.is_processed == True,
                        Transaction.timestamp >= wallet.created_at
                    )
                )
                
                volumes = result.one()
                
                wallet.buy_volume_lambo = float(volumes.buy_lambo)
                wallet.buy_volume_ton = float(volumes.buy_ton)
                wallet.buy_volume_usd = float(volumes.buy_usd)
                wallet.sell_volume_lambo = float(volumes.sell_lambo)
                wallet.sell_volume_ton = float(volumes.sell_ton)
                wallet.sell_volume_usd = float(volumes.sell_usd)
                wallet.total_volume_lambo = wallet.buy_volume_lambo + wallet.sell_volume_lambo
                wallet.total_volume_ton = wallet.buy_volume_ton + wallet.sell_volume_ton
                wallet.total_volume_usd = wallet.buy_volume_usd + wallet.sell_volume_usd
                
                wallet.sync_status = 'synced'
                wallet.initial_sync_completed = True
                
                await db.commit()
                
                from src.services.leaderboard_service import update_leaderboard
                update_leaderboard(wallet.address, wallet.total_volume_usd)
                
                logger.info(
                    f"‚úÖ Synced {wallet.address[:8]}... "
                    f"from {volumes.tx_count} tx, "
                    f"USD: ${wallet.total_volume_usd:.2f}"
                )
            
            return len(wallets)
    
    async def process_pending_transactions(self) -> int:
        async with self.processing_lock:
            async with async_session_maker() as db:
                result = await db.execute(
                    select(Transaction)
                    .where(Transaction.is_processed == False)
                    .order_by(Transaction.timestamp.asc())
                    .limit(self.batch_size)
                )
                transactions = result.scalars().all()
                
                if not transactions:
                    return 0
                
                processed_count = 0
                for tx in transactions:
                    try:
                        success = await self.processor.process_transaction(tx, db)
                        if success:
                            processed_count += 1
                        
                        await asyncio.sleep(self.delay)
                        
                    except Exception as e:
                        logger.error(f"Error processing tx {tx.tx_hash}: {e}")
                        await asyncio.sleep(self.delay)
                
                return len(transactions)
    
    async def ensure_leaderboard_ready(self):
        try:
            from src.services.leaderboard_service import get_total_wallets
            
            total = get_total_wallets()
            
            if total == 0:
                logger.warning("‚ö†Ô∏è  Redis leaderboard is empty! Rebuilding from database...")
                async with async_session_maker() as db:
                    from src.services.leaderboard_service import rebuild_leaderboard_from_db
                    result = await rebuild_leaderboard_from_db(db)
                    if result.get("rebuilt"):
                        logger.info(f"‚úÖ Leaderboard initialized: {result}")
                    else:
                        logger.warning(f"‚ö†Ô∏è  Failed to rebuild leaderboard: {result}")
            else:
                logger.info(f"‚úÖ Redis leaderboard ready: {total} wallets")
        except Exception as e:
            logger.error(f"‚ùå Error ensuring leaderboard ready: {e}")


async def main():
    tracker = JettonTracker()
    
    try:
        await tracker.start()
    except KeyboardInterrupt:
        logger.info("Received shutdown signal")
        await tracker.stop()


if __name__ == "__main__":
    asyncio.run(main())
